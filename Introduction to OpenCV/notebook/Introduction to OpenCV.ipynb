{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b386/5bbd3d87-fd8f-432d-877e-7e9fcdcdb57b/file.png)\n",
    "\n",
    "\n",
    "OpenCV (Open source computer vision) is an open source dedicated computer vision and machine learning software library. It aims to provide image and video analysis functionalities to build applications related to the field of computer vision. It includes a comprehensive set of both classic and state-of-the-art computer vison and machine learning algorithm implementations.Over the years with the help of OpenCV computers are now able to perform tasks such as detect and recognize faces, identify objects, classify human actions in videos, track camera movements, track moving objects, extract 3D models of objects, produce 3D point clouds from stereo cameras, stitch images together to produce a high resolution image of an entire scene and a lot more.\n",
    "\n",
    "\n",
    "There are interfaces build around for OpenCV functionality usage. Officially OpenCV has released two types of Python interfaces, `cv` and `cv2`. Later on the development of `cv` was kept on halt. Now with the latest release `cv2` module has a subclass of `cv` inside it which can be accessed.\n",
    "\n",
    "While dealing with package `cv2` everything is returned as NumPy objects like ndarray and native Python objects like lists,tuples,dictionary, etc. So due to this NumPy support, you can do any numpy operation here. NumPy is a highly stable and fast array processing library.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel Representation\n",
    "\n",
    "A digital image is nothing more than data—numbers indicating variations of red, green, and blue at a particular location on a grid of pixels. Most of the time, we view these pixels as miniature rectangles sandwiched together on a computer screen.\n",
    "\n",
    "In general there are two ways to represent the pixels : grayscale and color. \n",
    "\n",
    "In Grayscale pixel representation the pixel has a value ranging from 0 to 255. Where zero represents the color `black` and 255  represents for color `white` and all the values that lies between 0 and 255 are representing varying shades of gray. \n",
    "\n",
    "\n",
    "\n",
    "In colored pixel representation each pixel is represented in RGB color space - one value for the Red component, one for Green and one for Blue. Every component has a value ranging from 0 to 255 which indicates the strenght of that color there is.When combined these values into an RGB tuple in the form (red, green, blue). This tuple represents our color.\n",
    "\n",
    "![RGB](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b843/cbc5f89d-4524-4e20-a1b0-8c55edaa2296/file.png)\n",
    "\n",
    "\n",
    "\n",
    "OpenCV allows you to access every single pixel value which is nothing but a numpy array value. \n",
    "\n",
    "**Note that OpenCV stores RGB channels in reverse order that is it would be stored in BGR order.**\n",
    "\n",
    "It's time to access the pixels and manipulate them.\n",
    "\n",
    "```python\n",
    "# accessing pixels at coordinate (0,0)\n",
    "(b, g, r) = img[0, 0]\n",
    "print('Pixel at (0, 0) - Red: {}, Green: {}, Blue: {}'.format(r, g, b)) #print out the values of that location\n",
    "\n",
    "# manipulating the pixel at (0,0) \n",
    "img[0,0] = (0, 0 , 255) #setting the color to be pure red as red has the value 255\n",
    "(b, g, r) = img[0, 0]\n",
    "print('Pixel at (0, 0) - Red : {}, Green: {}, Blue: {}'.format(r, g, b)) #print out the modified values of that location\n",
    "\n",
    "Output of orginal pixel values: Pixel at (0, 0) - Red: 44, Green: 43, Blue: 39\n",
    "Output of modified pixel values : Pixel at (0, 0) - Red : 255, Green: 0, Blue: 0\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "This is just one pixel value that is manipulated if we want to modify an entire region of several pixel values we can just select that region and apply these changes similarily as follows -\n",
    "\n",
    "```python\n",
    "RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #converting BGR to RGB format\n",
    "RGB_img[0:100, 0:100] = (0, 255, 0)#selecting 100 * 100 region from the image and then assigning the green color to it\n",
    "plt.imshow(RGB_img)\n",
    "```\n",
    "Output : \n",
    "![pixel_manipulate_messi](https://storage.googleapis.com/ga-commit-live-prod-live-data/account/b92/11111111-1111-1111-1111-000000000000/b996/ac01646c-a4cb-46fc-8dd9-22acd021d661/file.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We have used `cv2.cvtColor` functionality of OpenCV that essentially converts image from one color space to another. Since the default color format in OpenCV is interpreted in RGB but it is actually BGR (as the OpenCV librarty has been built with fixing BGR format as the basic format to interpret image) .Hence we use `cv2.COLOR_BGR2RGB` which changes the color space from BGR to RGB.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "# !pip install opencv-python     #uncomment and run the line to install OpenCV library\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translations\n",
    "\n",
    "Translation of an image is a technique involving shifting of an image along the x and y axis. With the help of this technique we can shift an image up, down, left or right, along with any combination of the above.\n",
    "\n",
    "This an affine transform that simply shifts the position of an image.\n",
    "\n",
    "We use cv2.warpAffine to implement these transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotations\n",
    "\n",
    "This technique involves rotating an image by some angle $\\theta$. Rotation is useful for scenarios to provide variation to existing data thereby making machine learning models more robust to the data variation. Also this rotation can be applied in the pre-processing stage while building a computer vision application to make sure that the data is consistent in terms of $\\theta$.\n",
    "\n",
    "Let's explore how we can rotate an image with the help of OpenCV.\n",
    "\n",
    "\n",
    "\n",
    "cv2.getRotationMatrix2D(rotation_center_x, rotation_center_y, angle of rotation, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing\n",
    "\n",
    "`Resizing` or scaling as we call it is a technique to increase or reduce the size of an image. Web browsers, image editors, image and file viewers are among the various applications of image scaling or resizing is being applied.\n",
    "\n",
    "Let's now look at how can we perform it on the image.\n",
    "\n",
    "Re-sizing is very easy using the cv2.resize function, it's arguments are:\n",
    "```python\n",
    "cv2.resize(image, dsize(output image size), x scale, y scale, interpolation)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic Operations\n",
    "\n",
    "Image Arithmetic comprise of several techniques to perform basic airthmetic operations such as additon, subtraction, multiplication and divison on images. This technique has many use cases in image processing both as a prelimnary step in more complex operation and by itself. For example, image subtraction can be used to detect the differences between two or more images of the same scence or object.\n",
    "\n",
    "Following code snippets will be guiding you through different image arithmetic operations.We will start off with introducing what happens if we add or subtract two or more images using OpenCV.\n",
    "Image Addition and Subtraction\n",
    "\n",
    "Before jumping straight to the additon or subtraction of images directly let's discuss what happens if we are examining a pixel of value 251 and we try to add 12 to it.If we proceed by the approach of basic arithmetic rules we would end up adding having a total value of 263 but since RGB images are represented as 8-bit unsigned integers 263 is not a valid value same goes in the case of subtraction a value resulting from the basic subtraction attaining a negative pixel values is not valid when it comes to RGB images.\n",
    "\n",
    "There are two ways to handle the situation posed above:\n",
    "\n",
    "   * We can perform a check to ensure that no pixel falls outside the range of [0,255], thus clipping all pixels to have a minimum and maximum value of 0 and 255 respectively.\n",
    "\n",
    "   * Or we can apply a modulus operation and wrap around the values.\n",
    "\n",
    "Now you can go on implementing any of these two ways mentioned above depending upon how you want the desired results to be. But keep in mind that OpenCV will by default perform clipping and ensure that pixel values do not fall outside the range [0, 255] and using numpy will perform modulo airthmetic and 'wrap around'.\n",
    "\n",
    "These are simple operations that allow us to directly add or subract to the color intensity.\n",
    "\n",
    "Calculates the per-element operation of two arrays. The overall effect is increasing or decreasing brightness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blurring\n",
    "\n",
    "Image Blurring refers to making the image less clear or distinct. It is done with the help of various low pass filter kernels.\n",
    "\n",
    "Advantages of blurring:\n",
    "\n",
    "   * It helps in Noise removal. As noise is considered as high pass signal so by the application of low pass filter kernel we restrict noise.\n",
    "   * It helps in smoothing the image.\n",
    "   * Low intensity edges are removed.\n",
    "   * It helps in hiding the details when necessary. For e.g. in many cases police deliberately want to hide the face of the victim, in such cases blurring is required.\n",
    "\n",
    "Important types of blurring:\n",
    "\n",
    "    Gaussian Blurring:Gaussian blur is the result of blurring an image by a Gaussian function. It is a widely used effect in graphics software, typically to reduce image noise and reduce detail. It is also used as a preprocessing stage before applying our machine learning or deep learning models.\n",
    "    E.g. of a Gaussian kernel(3×3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face and Smile Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Include the desired haar-cascades.\n",
    "\n",
    "Haar-cascades are classifiers that are used to detect features (of face in this case) by superimposing predefined patterns over face segments and are used as XML files. In our model, we shall use face, eye and smile haar-cascades, which after downloading need to be placed in the working directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:  In this step, we are going to build main function which would be performing the smile detection.\n",
    "\n",
    "* The live feed coming from the webcam/video device is processed frame by frame. We process the gray scale image, as haar-cascades work better on them.\n",
    "* To detect the face, we use:\n",
    "```python\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "```\n",
    "where 1.3 is the scaling factor, and 5 is the number of nearest neighbors. We can adjust these factors as per our convenience/results to improve our detector.\n",
    "\n",
    "Now for each subsequent face detected, we need to check for smiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : \n",
    "\n",
    "We define main function in this step. After execution, the function can be terminated by pressing the “q” key.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
